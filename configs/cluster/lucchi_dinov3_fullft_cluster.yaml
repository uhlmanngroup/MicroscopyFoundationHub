# Environment: cluster (UZH Science) - Lucchi++ segmentation run
# DINOv3 LoRA config.

# ---- I/O ----
train_img_dir: "/home/cfuste/data/datasets/Lucchi++/Train_In"
train_mask_dir: "/home/cfuste/data/datasets/Lucchi++/Train_Out"
test_img_dir:    "/home/cfuste/data/datasets/Lucchi++/Test_In"
test_mask_dir:   "/home/cfuste/data/datasets/Lucchi++/Test_Out"

# results + experiment naming (stored under /data to persist on the cluster)
experiment_id: "2026-02-12_A1_lucchi_dinov3-vits16_fullft_seg"
results_root: "/home/cfuste/data/DINO-LoRA/dinov3/seg"
task_type: "lucchi-fullft"

# dataset pairing (Lucchi images are named maskXXXX vs masks as digits)
dataset:
  type: lucchi
  params:
    recursive: false
    image_prefix: "mask"
    zfill_width: 4

# ---- model / backbone ----
backbone:
  name: dinov3
  variant: vitl16
  load_backend: torchhub
  repo_dir: /home/cfuste/GitHub/dinov3
  weights: /home/cfuste/data/models/dinov3/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth
  preprocess:
    preset: em
dino_size: vits16
img_size:
  mode: longest_edge
  target: 1022   # largest <= 1024 while staying multiple of 16
  patch_multiple: 16
  rounding: floor
num_classes: 2

full_finetune: true

# ---- LoRA ----
use_lora: false
lora_rank: 16
lora_alpha: 32
lora:
  enabled: false
  target_policy: vit_attention_only
  layer_selection: all
  exclude: [head, decoder, seg_head]
  compatibility_mode: true

# ---- training ----
batch_size: 2          # tightened for low-memory smoke tests on standard GPUs
epochs: 1000
patience: 20
lr: 0.00005
weight_decay: 0.0001
num_workers: 0
device: auto
amp: false            # first run: stability check without AMP
val_ratio: 0.1
split_seed: 42

# ---- loss (CE + Tversky on foreground) ----
loss: dice      # ce, dice, ce_tversky
class_weights: [1.0, 15.0]    # bg, fg
tversky_alpha: 0.7
tversky_beta: 0.3
tversky_eps: 1.0e-6
tversky_weight: 0.6   # lambda: 0.6*Tversky + 0.4*CE

# ---- training safety ----
clip_grad_norm: 1.0   # global grad clip

# ---- export / viz (kept; argmax is used for CE path) ----
binarize: true
binarize_threshold: 128
